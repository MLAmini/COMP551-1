{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parse covariance matrix data\n",
    "cov1 = pandas.read_csv('./dataset/DS2_Cov1.txt', header=None)\n",
    "cov1.drop([20], axis=1, inplace=True)\n",
    "cov1 = cov1.values\n",
    "\n",
    "cov2 = pandas.read_csv('./dataset/DS2_Cov2.txt', header=None)\n",
    "cov2.drop([20], axis=1, inplace=True)\n",
    "cov2 = cov2.values\n",
    "\n",
    "cov3 = pandas.read_csv('./dataset/DS2_Cov3.txt', header=None)\n",
    "cov3.drop([20], axis=1, inplace=True)\n",
    "cov3 = cov3.values\n",
    "\n",
    "#Parse the mean vectors\n",
    "c1_m1 = numpy.genfromtxt('./dataset/DS2_c1_m1.txt', delimiter=',')[:-1]\n",
    "c1_m2 = numpy.genfromtxt('./dataset/DS2_c1_m2.txt', delimiter=',')[:-1]\n",
    "c1_m3 = numpy.genfromtxt('./dataset/DS2_c1_m3.txt', delimiter=',')[:-1]\n",
    "\n",
    "c2_m1 = numpy.genfromtxt('./dataset/DS2_c2_m1.txt', delimiter=',')[:-1]\n",
    "c2_m2 = numpy.genfromtxt('./dataset/DS2_c2_m2.txt', delimiter=',')[:-1]\n",
    "c2_m3 = numpy.genfromtxt('./dataset/DS2_c2_m3.txt', delimiter=',')[:-1]\n",
    "\n",
    "c1_m = [c1_m1, c1_m2, c1_m3]\n",
    "c2_m = [c2_m1, c2_m2, c2_m3]\n",
    "cov = [cov1, cov2, cov3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) generate 2000 examples and split data\n",
    "ds1 = []\n",
    "ds0 = []\n",
    "\n",
    "\n",
    "for i in range(len(weight)):\n",
    "    for j in range(int(2000 * weight[i])):\n",
    "        ds1.append(numpy.random.multivariate_normal(c1_m[i], cov[i]))\n",
    "        ds0.append(numpy.random.multivariate_normal(c2_m[i], cov[i]))\n",
    "\n",
    "\n",
    "ds1 = pandas.DataFrame(ds1)\n",
    "ds0 = pandas.DataFrame(ds0)\n",
    "ds0[20] = 0\n",
    "ds1[20] = 1\n",
    "\n",
    "msk = numpy.random.rand(len(ds1)) <= 0.7\n",
    "train1 = ds1[msk]\n",
    "test1 = ds1[~msk]\n",
    "\n",
    "msk = numpy.random.rand(len(ds0)) <= 0.7\n",
    "train0 = ds0[msk]\n",
    "test0 = ds0[~msk]\n",
    "\n",
    "train = pandas.concat([train0, train1], ignore_index=True)\n",
    "test = pandas.concat([test0, test1], ignore_index=True)\n",
    "\n",
    "train1.to_csv('DS2_train1.csv')\n",
    "test1.to_csv('DS2_test1.csv')\n",
    "train0.to_csv('DS2_train0.csv')\n",
    "test0.to_csv('DS2_test0.csv')\n",
    "\n",
    "test.to_csv('DS2_test.csv')\n",
    "train.to_csv('DS2_train.csv')\n",
    "\n",
    "len0 = len(train0)\n",
    "len1 = len(train1)\n",
    "\n",
    "# drop the output column\n",
    "train0 = train[train[20] == 0]\n",
    "train0 = train0[train0.columns.difference([20])]\n",
    "\n",
    "train1 = train[train[20] == 1]\n",
    "train1 = train1[train1.columns.difference([20])]\n",
    "\n",
    "test_output = test[20]\n",
    "test.drop([20], axis=1, inplace=True)\n",
    "\n",
    "train_output = train[20]\n",
    "train.drop([20], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Part 1 - LDA \n",
      "\n",
      "w0:  -0.0569913782536\n",
      "w1: [-0.017668708739546859, 0.00082180339369740396, -0.010911708309174234, -0.014140645497999232, 0.0018118540105475089, 0.013147803222069408, -0.072973666070591414, -0.055532720290826822, 0.045972060724450967, 0.038857437085685204, 0.052508302358376391, -0.011595949743686197, -0.017630146958210496, 0.014781821013132176, -0.0044705088773484003, 0.11013250172959704, 0.036709526429887195, -0.0079289650954868646, 0.033367114372139975, -0.093249860854418831]\n",
      "\n",
      "[[  -1.    0.    1.]\n",
      " [ 274.  620.  297.]]\n",
      "True positive: 318.0\n",
      "True negative: 302.0\n",
      "\n",
      "F measure: 0.526926263463\n",
      "Accuracy: 0.520570948783\n",
      "Precision: 0.517073170732\n",
      "Recall: 0.537162162162\n"
     ]
    }
   ],
   "source": [
    "# estimated max probability\n",
    "print(\"\\n\\nPart 1 - LDA \\n\")\n",
    "prob_0 = float(len0) / float(len0 + len1)\n",
    "prob_1 = 1.0 - prob_0\n",
    "\n",
    "\n",
    "mean_0 = numpy.array(train0.mean())\n",
    "mean_1 = numpy.array(train1.mean())\n",
    "\n",
    "diff_0 = numpy.array(train0 - mean_0)\n",
    "diff_1 = numpy.array(train1 - mean_1)\n",
    "\n",
    "coeff_0 = numpy.matmul(diff_0.T, diff_0)\n",
    "coeff_1 = numpy.matmul(diff_1.T, diff_1)\n",
    "\n",
    "coeff = (coeff_0 + coeff_1) / float(len0 + len1)\n",
    "\n",
    "covm_0 = numpy.matmul(numpy.linalg.pinv(coeff), mean_0)\n",
    "mcovm_0 = numpy.matmul(mean_0.T, covm_0)\n",
    "\n",
    "covm_1 = numpy.matmul(numpy.linalg.pinv(coeff), mean_1)\n",
    "mcovm_1 = numpy.matmul(mean_1.T, covm_1)\n",
    "\n",
    "w0 = math.log(prob_0) - math.log(prob_1) - 1 / 2 * (mcovm_0 - mcovm_1)\n",
    "w1 = numpy.matmul(numpy.linalg.pinv(coeff), mean_0 - mean_1)\n",
    "\n",
    "\n",
    "print(\"w0: \", w0)\n",
    "print(\"w1: \" + str([i for i in w1]) + \"\\n\")\n",
    "\n",
    "pred = numpy.matmul(test, w1) + w0\n",
    "\n",
    "# replace dec_bound to 0 and 1\n",
    "pred[pred > 0] = 0\n",
    "pred[pred < 0] = 1\n",
    "\n",
    "error_matrix = pred - test_output\n",
    "\n",
    "elem, cnt = numpy.unique(error_matrix, return_counts=True)\n",
    "\n",
    "print(numpy.asarray([elem, cnt]))\n",
    "\n",
    "'''\n",
    "1 => false positive\n",
    "0 => correct prediction\n",
    "-1 => false negative\n",
    "'''\n",
    "\n",
    "fp = cnt[2]\n",
    "fn = cnt[0]\n",
    "\n",
    "\n",
    "tp = numpy.sum(pred.dot(test_output))\n",
    "print(\"True positive: \" + str(tp))\n",
    "\n",
    "pred = pred - 1\n",
    "test_output_temp = test_output - 1\n",
    "tn = numpy.sum(pred.dot(test_output_temp))\n",
    "print(\"True negative: \" + str(tn))\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "\n",
    "F = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"\\nF measure: \" + str(F))\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "print(\"Precision: \" + str(precision))\n",
    "print(\"Recall: \" + str(recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Part 2 - K NN\n",
      "\n",
      "[0.51217464315701089, 0.52560873215785053, 0.53232577665827041, 0.52141057934508817, 0.53148614609571787, 0.53736356003358521, 0.53316540722082284, 0.52392947103274556, 0.53484466834592781, 0.53232577665827041, 0.52812762384550793, 0.53400503778337527, 0.53064651553316544, 0.53232577665827041, 0.51889168765743077, 0.5272879932829555, 0.51553316540722083, 0.5298068849706129, 0.5247691015952981, 0.52812762384550793, 0.52141057934508817, 0.52308984047019313, 0.52225020990764059, 0.51637279596977326, 0.5172124265323258, 0.52392947103274556, 0.51217464315701089, 0.5272879932829555, 0.52560873215785053, 0.52392947103274556, 0.53400503778337527, 0.52644836272040307, 0.52896725440806047, 0.5247691015952981, 0.52644836272040307, 0.5298068849706129, 0.52644836272040307, 0.52896725440806047, 0.52141057934508817, 0.52896725440806047, 0.53400503778337527, 0.53736356003358521, 0.54072208228379515, 0.53988245172124261, 0.54827875734676745, 0.54995801847187242, 0.54156171284634758, 0.54072208228379515, 0.53232577665827041]\n",
      "\n",
      "Best k = 46\n",
      "\n",
      "Accuracy = 0.549958018472\n",
      "Precision = 0.49493243243243246\n",
      "Recall = 0.5528301886792453\n",
      "F - measure = 0.5222816399286987\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nPart 2 - K NN\\n\")\n",
    "\n",
    "\n",
    "res_step = []\n",
    "accuracy_step = []\n",
    "\n",
    "\n",
    "for k in range(1, 50):\n",
    "    # metrics = [tp, tn, fp, fn]\n",
    "    metrics = [0, 0, 0, 0]\n",
    "    for i in range(len(test)):\n",
    "        dist = abs(train.sub(numpy.array(numpy.array(test.loc[[i], :])[0])))\n",
    "        dist = numpy.array(numpy.power(dist, 2).sum(axis=1))\n",
    "\n",
    "        # select the k training examples closest to the test example\n",
    "        ind = numpy.argpartition(dist, k)[:k]\n",
    "\n",
    "        # predict value of test output using the average of the k training outputs\n",
    "        dec = 1 if (numpy.array([train_output[i] for i in ind]).mean() > 0.5) else 0\n",
    "\n",
    "        #update metrics\n",
    "        if dec == test_output[i] == 1:\n",
    "            metrics[0] += 1\n",
    "        elif dec == test_output[i] == 0:\n",
    "            metrics[1] += 1\n",
    "        elif dec != test_output[i] == 1:\n",
    "            metrics[2] += 1\n",
    "        else:\n",
    "            metrics[3] += 1\n",
    "\n",
    "    res_step.append(metrics)\n",
    "    accuracy_step.append((metrics[0] + metrics[1]) / numpy.sum(metrics))\n",
    "print(accuracy_step)\n",
    "\n",
    "print(\"\\nBest k = \" + str(accuracy_step.index(max(accuracy_step)) + 1))\n",
    "\n",
    "metrics = res_step[accuracy_step.index(max(accuracy_step))]\n",
    "tp = metrics[0]\n",
    "tn = metrics[1]\n",
    "fp = metrics[2]\n",
    "fn = metrics[3]\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "\n",
    "F = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"\\nAccuracy = \" + str(max(accuracy_step)))\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))\n",
    "print(\"F - measure = \" + str(F))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
